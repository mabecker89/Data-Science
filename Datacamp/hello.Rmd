---
title: "Untitled"
author: "Marcus Becker"
date: "November 7, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Chapter 3: Logistic Regression

Logistic regression involves fitting a curve to numeric data to make predictions about binary events.

We use a logistic function - an S-shaped curved - so that predictions can't be less than 0 or more than 1 (just like a probability).

```{r}

library(tidyverse)
library(pROC)

# Fundraising data set. 
donors <- read_csv("https://assets.datacamp.com/production/repositories/718/datasets/9055dac929e4515286728a2a5dae9f25f0e4eff6/donors.csv")

str(donors)
table(donors$donated)

# Fit a logistic regression model:
donation_model <- glm(data = donors, 
                      formula = donated ~ bad_address + interest_religion + interest_veterans,
                      family = "binomial")

summary(donation_model)

# Using predict() - by default is in log-odds - unless type = "response" is specified. Converts log-odds to probabilities.
donors$donation_prob <- predict(donation_model, type = "response")

# Find the donation probability of the average prospect in the dataset
mean(donors$donated)

# Predict a donation if probability of donation is greater than average
donors$predicted <- ifelse(donors$onation_prob > mean(donors$donated), 1, 0)

# Calculate the model's accuracy
mean(donors$donated == donors$predicted)

```

Accuracy can be misleading, especially for imbalanced datasets.

What classification threshold should we choose? 0.5? Or one of many others.
Solution: let the computer calculate/plot the true/false positive rate at every possible threshold. 

Let's try a ROC curve. 

```{r}

# Create ROC curve - actual, predicted
ROC <- roc(donors$donated, donors$donation_prob)

plot(ROC, col = "blue")

auc(ROC)

```

Dummy variables, missing data, and interactions.

- Dummy variables for categorical variables. 
- Imputing missing data with a guess about what the value will be.
- Interaction effect - two predictors, when combined, will have a different impact than the sum of their individual impacts combined. 

```{r}

# So wealth_rating is coded as numeric. However, it should be factor.
summary(glm(data = donors, formula = donated ~ wealth_rating, family = "binomial"))

# Recode:
donors$wealth_rating <- factor(donors$wealth_rating, 
                               levels = c(0,1,2,3), 
                               labels = c("Unknown", "Low", "Medium", "High"))

# Relevel using Medium as the reference category:
donors$wealth_rating <- relevel(donors$wealth_rating, ref = "Medium")

# Try the modeling again:
summary(glm(data = donors, formula = donated ~ wealth_rating, family = "binomial"))

# Missing data - the model will leave out observations with missing variables in any of the predictors.
# In this case, some prospective donors have missing age data.

summary(donors$age) # removes NA's.
# Impute age (just using the mean)
donors$imputed_age <- ifelse(is.na(donors$age), round(mean(donors$age, na.rm = TRUE), digits = 2), donors$age)
# And also created another variable to indicate whether it was missing.
donors$missing_age <- ifelse(is.na(donors$age), 1, 0)

# Interactions
rfm_model <- glm(data = donors, formula = donated ~ money + recency*frequency, family = "binomial")

summary(rfm_model)

rfm_prob <- predict(rfm_model, type = "response")

ROC <- roc(donors$donated, rfm_prob)

plot(ROC, col = "red")

auc(ROC)

```

Automatic feature selection

Stepwise regression
- backward deletion
- forward selection

```{r}

# Build null model first
null_model <- glm(data = donors, formula = donated ~ 1, family = "binomial")
# Specify full model using all of the potential predictors
full_model <- glm(data = donors, formula = donated ~ ., family = "binomial")

# Use a forward stepwise algorithm to build a model:
step_model <- step(null_model, scope = list(lower = null_model, upper = full_model), direction = "forward")


```


















